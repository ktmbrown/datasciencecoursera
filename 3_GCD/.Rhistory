# bind columns of two vectors to create a matrix
x <- 1:4
y<-10:13
cbind(x,y)
nrow(cbind(x,y))
nrow(cbind(x,y))
ncol(cbind(x,y))
rbind(x,y)
df1
df1=as.data.frame((cbind(x,y))) #convert to a data frame
df1
str(df1)
install.packages(datasets)
install.packages("datasets")
installed.packages()
length(df1)
data()
data(package="datasets")
data()
data("ChickWeight")
str(ChickWeight)
head(ChickWeight)
typeof(ChickWeight['Chick'])
typeof(ChickWeight.Diet)
typeof(ChickWeight[Diet])
knitr::opts_chunk$set(echo = TRUE)
# Setting working directory
setwd("C:\\Users\\kbrown5\\Documents\\Data_Science\\Statistics")
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
View(married_sal)
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
# View the head
head(married_sal)
# View the structure
str(married_sal)
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
# View the head
head(married_sal)
# Read in text file
married_sal2<-read.table("family-households-with-married-couples.txt",header=T)
# View the head
head(married_sal2)
# View the structure
str(married_sal2)
red_wine<-read.csv("winequality-red.csv", header=T, sep=';')
install.packages(readxl)
installed.packages()
install.packages('readx;')
install.packages('readxl')
library(readxl)
a <- array(rnorm(2*2*10), c(2,2,10))
a
apply(a,c(1,2), mean'')
apply(a,c(1,2), mean)
x <- matrix(rnorm(200),20,10)
x
apply(x,1,sum)
x[,1]
mean(x[,1])
sum(x[,])
sum(x[,1])
x
apply(x,1,sum)
apply(x,2,sum)
rowSums(x)
colSums(x)
x
apply(x,1,quantile,probs=c(0.25,0.75))
quantile(x[1,],probs=0.25)
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
f
split(x,f)
l1 <- split(x,f)
l1
l1$1
l1[1]
l1[2]
library(datasets)
data(iris)
?iris
head(iris)
factor(iris$Species)
tapply(iris,iris$Species,mean)
tapply(iris$Sepal.Length,iris$Species,mean)
iris(head)
head(iris)
colmeans(iris)
colMeans(iris)
colMeans(iris)
apply(iris[, 1:4], 2, mean)
class(apply(iris[, 1:4], 2, mean))
library(datasets)
data(mtcars)
head(mtcars)
tapply(mtcars$mpg,mtcars$cyl,mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(mtcars, cyl, mean)
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
head(mtcars)
tapply(mtcars$hp,mtcars$cyl,mean)
x <- tapply(mtcars$hp,mtcars$cyl,mean)
y <- x[1] - x[3]
debug(ls)
?ks
?ls
exit()
## xml
library(httr)
library(XML)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/beds-1/baths-1/pg-2'
r = GET(fileURL)
doc <- htmlTreeParse(fileURL, useInternal=TRUE, isURL=T)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(fileURL, useInternal=TRUE, isURL=T)
doc <- htmlTreeParse(r, useInternal=TRUE, isURL=T)
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
?GET
## xml
library(httr)
library(XML)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
doc <- xmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
street <- xpathSApply(doc, "//span[@class='listing-street-address']",xmlValue)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(r, useText = TRUE)
doc <- htmlTreeParse(r, asText = TRUE)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
content2 <- content(r,as="text")
content
?content
content2 <- content(r,as="text",encoding="UTF-8")
doc <- htmlParse(content2, asText = TRUE)
street <- xpathSApply(doc, "//span[@class='listing-street-address']",xmlValue)
city <- xpathSApply(doc, "//span[@class='listing-city']",xmlValue)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url,destfile = 'idaho_microdata.csv',method = 'curl')
id_df <- read.csv('idaho_microdata.csv')
gdp_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(gdp_url, destfile = 'gdp.csv',method='curl')
gdp_df <- read.csv('gdp.csv')
edu_df <- read.csv('edu.csv')
edu_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(edu_url, destfile = 'edu.csv', method='curl')
edu_df <- read.csv('edu.csv')
head(gdp_df)
getwd()
setwd("C:/Users/kbrown5/Documents/Data_Science/datasciencecoursera/3_GCD")
gdp_df <- read.csv('gdp.csv')
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
?read.csv
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(edu_df)
head(edu_df)
head(gdp_df)
tail(gdp_df)
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
head(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x = "CountryCode")
head(merge_data)
merge_data <- merge(gdp_df,edu_df,by.x = "CountryCode",by.y="CountryCode")
head(merge_data)
merge_data <- merge(gdp_df,edu_df.by.y="CountryCode")
merge_data <- merge(gdp_df,edu_df,by.y="CountryCode")
View(merge_data)
sorted_data <- arrange(merge_data,desc(Ranking))
tail(sorted_data)
tail(gdp_df)
tail(gdp_df,20)
gdp_r <- gdp_df[1:214,]
tail(gdp_r)
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
sorted_data[13]
names(sorted_data)
sorted_data[13,5]
summarize(sorted_data)
View(sorted_data)
View(merge_data)
View(sorted_data)
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
View(income.groups)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
?dplyr
?cut
gdp_groups <- cut(merge_data$Ranking, breaks=quantile(merge_data$Ranking))
gdp_groups <- cut(merge_data$Ranking, breaks=quantile(merge_data$Ranking,na.rm = TRUE))
table(gdp_groups)
gdp_groups <- cut(merge_data$Ranking, breaks=quantile(merge_data$Ranking,probs = c(.20,.40,.60,.80),na.rm = TRUE))
table(gdp_groups)
gdp_groups <- cut(merge_data$Ranking, breaks=5)
table(gdp_groups)
merge_data$gdp_groups <- cut(merge_data$Ranking, breaks=5)
head(merge_data)
table(merge_data$gdp_groups)
table(merge_data$gdp_groups,merge_data$Income.Group)
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
sorted_data[13,5]
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url,destfile = 'idaho_microdata.csv',method = 'curl')
id_df <- read.csv('idaho_microdata.csv')
head(id_df)
id_df$ACR == 3 && id_df$AGS == 6
agricultureLogical <- id_df$ACR == 3 & id_df$AGS == 6
id_df[which(agricultureLogical),]
id_df[which(agricultureLogical),]
head(id_df[which(agricultureLogical),],3)
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
install.packages('jpeg')
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
gdp_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(gdp_url, destfile = 'gdp.csv',method='curl')
edu_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(edu_url, destfile = 'edu.csv', method='curl')
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
names(gdp_df)
names(edu_df)
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
gdp_r <- gdp_df[1:214,]
names(gdp_df)
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
names(gdp_df)
names(edu_df)
head(gdp_df)
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode",by.x="X")
merge_data <- merge(gdp_df,edu_df,by.y="CountryCode",by.x="X")
View(merge_data)
View(merge_data)
sorted_data <- arrange(merge_data,desc(Ranking))
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
table(income.groups)
head(edu_df)
table(income.groups)
merge_data <- merge(gdp_df,edu_df,by.x="X")
gdp_df <- rename(gdp_df, CountryCode = X)
names(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
names(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
View(sorted_data)
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
income.groups
# finding average GPD ranking among different income groups
income.groups <- group_by(sorted_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
gdp_df <- read.csv('gdp.csv',na.strings = c("..",""))
gdp_df <- rename(gdp_df, CountryCode = X)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
head(sorted_data)
View(sorted_data)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
View(merge_data)
View(sorted_data)
gdp_df <- read.csv('gdp.csv')
edu_df <- read.csv('edu.csv')
gdp_df <- rename(gdp_df, CountryCode = X)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
head(sorted_data)
gdp_df <- read.csv('gdp.csv', stringsAsFactors = FALSE)
gdp_df <- rename(gdp_df, CountryCode = X)
names(gdp_df)
class(gdp_df$Ranking)
gdp_df$Ranking<-as.numeric(gdp_df$Ranking)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
head(sorted_data
)
View(sorted_data)
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
names(edu_df)
library(dplyr)
gdp_df <- read.csv('gdp.csv', skip = 4)
gdp_df$X.4 <- as.numeric(gsub(',','',gdp_df$X.4))
gdp_df1 <- gdp_df[1:190,c(1,2,4,5)]
gdp_df <- read.csv('gdp.csv', skip = 4)
gdp_df1 <- gdp_df[1:190,c(1,2,4,5)]
View(gdp_df)
getwd()
gdp_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(gdp_url, destfile = 'gdp.csv',method='curl')
gdp_df <- read.csv('gdp.csv', skip = 4)
gdp_df$X.4 <- as.numeric(gsub(',','',gdp_df$X.4))
gdp_df1 <- gdp_df[1:190,c(1,2,4,5)]
mean(gdp_df1$X.4)
gdp_df <- rename(gdp_df1, CountryCode = X)
head(gdp_df)
gdp_df <- rename(gdp_df1, Ranking = X.1)
head(gdp_df)
gdp_df <- rename(gdp_df1, CountryName = X.3)
gdp_df <- rename(gdp_df1, gdpInMillions = X.4)
class(gdp_df$gdpInMillions)
head(gdp_df)
gdp_df <- rename(gdp_df1, CountryCode = X)
gdp_df <- rename(gdp_df1, Ranking = X.1)
gdp_df <- rename(gdp_df1, CountryName = X.3)
head(gdp)
head(gdp_df)
gdp_df <- rename(gdp_df1, CountryCode = X)
gdp_df <- rename(gdp_df1, Ranking = X.1)
gdp_df <- rename(gdp_df1, CountryName = X.3)
gdp_df <- rename(gdp_df1, gdpInMillions = X.4)
names(edu_df)
edu_df <- read.csv('edu.csv')
names(edu_df)
head(gdp_df)
gdp_df <- rename(gdp_df1, CountryCode = X)
head(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
View(merge_data)
names(edu_df)
edu_df$National.accounts.base.year
grep("June", merge_data$Special.Notes)
grep("June", merge_data$Special.Notes, value = TRUE)
grep("Fiscal year end: June 30", merge_data$Special.Notes, value = TRUE)
grep("Fiscal year end: June", merge_data$Special.Notes, value = TRUE)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages('quantmod')
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
View(amzn)
sampleTimes
table(grepl("2012", sampleTimes))
days <- format(sampleTimes,%a)
days <- format(sampleTimes,"%a")
table(grepl("Mon",days))
grep("2012",sampleTims)
grep("2012",sampleTimes)
dates_2012 <- grep("2012",sampleTimes)
days <- format(dates_2012,"%a")
dates_2012 <- grep("2012",sampleTimes)
dates_2012
table(grepl("2012", sampleTimes))
dates_2012 <- sampleTimes[grep("2012",sampleTimes)]
days <- format(dates_2012,"%a")
mon_2012 <- table(grepl("Mon"),days)
mon_2012 <- table(grepl("Mon",days))
table(grepl("Mon",days))
?unzip
getw()
getwd()
# Getting data from website
if(!file.exists("./data")){dir.creat("./data")}
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
download.file(url, destfile = './data/activity.zip',method='curl' )
unzip('./data/activity.zip')
unzip('./data/activity.zip',expDir='./data')
unzip('./data/activity.zip',exdir = './data')
getwd()
setwd("/Users/katiebrown/Documents/DS/datasciencecoursera/")
test <- read.csv("test.csv")
View(test)
names(test)
head(test$Activity,30)
unzip('./data/activity.zip',exdir = './data')
# Getting data from website
if(!file.exists("./data")){dir.creat("./data")}
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip'
download.file(url, destfile = './data/activity.zip',method='curl' )
unzip('./data/activity.zip',exdir = './data')
?file.rename
getwd()
setwd("/Users/katiebrown/Documents/DS/datasciencecoursera/3_GCD")
unzip('./data/activity.zip',exdir = './data')
file.rename('./data/UCI_HAR_Dataset','./data/UCI')
file.rename('./data/UCI_HAR_Dataset/','./data/UCI/')
file.rename('./data/UCI HAR Dataset/','./data/UCI/')
x_test <- read.delim(file, sep = "\t")
# read in x_test
file <- './data/UCI/X_test.txt'
x_test <- read.delim(file, sep = "\t")
# read in x_test
file <- './data/UCI/test/X_test.txt'
x_test <- read.delim(file, sep = "\t")
View(x_test)
file <- './data/UCI/test/X_test.txt'
x_test <- read.delim(file, sep = " ")
View(x_test)
x_test <- read.lines(file)
x_test <- readlines(file)
x_test <- readLines(file)
head(x_test)
x_test <- read.csv(file)
x_test <- read.csv(file)
View(x_test)
x_test <- read.delim(file, sep='\t')
View(x_test)
x_test <- read.delim(file, sep='\t',header=FALSE)
View(x_test)
?strsplit
x_test <- trim(x_test)
# read in x_test
# library(stringr)
file <- './data/UCI/test/X_test.txt'
# read in x_test
library(stringr)
x_test <- str_trim(x_test)
View(test)
strsplit(x_text, " ")
x_test <- read.delim(file, sep='\t',header=FALSE)
x_test2 <- strsplit(x_test, " ")
x_test2 <- strsplit(x_test, ' ')
x_test2 <- strsplit(x_test, '\s')
x_test2 <- strsplit(x_test, " (?=[^ ]+$)")
View(x_test)
View(test)
x_test <- read.fwf(file,widths=c(15,15,15,15,15))
View(x_test)
x_test <- read.fwf(file,widths=c(16,16,16,16,16))
View(x_test)
class(x_test$V2)
file2 <- './data/UCI/test/y_test.txt'
file2
x_labels <- read.fwf(file,widths=x(1))
x_labels <- read.fwf(file,widths=c(1))
View(x_labels)
x_labels <- read.fwf(file2 ,widths=c(1))
View(x_labels)
class(x_labels)
class(x_labels$V1)
x_labels <- as.factor(x_labels$V1)
levels(x_labels) <- c('WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS',
'SITTING','STANDING','LAYING')
class(x_labels)
levels(x_labels)
x_labels
Activity <- as.factor(x_labels$V1)
levels(Activity) <- c('WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS',
'SITTING','STANDING','LAYING')
x_labels <- as.factor(x_labels$V1)
Activity <- x_labels
x_df <- cbind(x_test,Activity)
View(x_df)
x_df[33,2]
