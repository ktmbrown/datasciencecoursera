library(caret)
install.packages(caret)
x<-c(1,2,3)
y<-c(4,5,6)
z<-c(x,y)
9+9
setwd("C:\Users\kbrown5\Documents\Data_Science\Statistics")
setwd("C:\\Users\\kbrown5\\Documents\\Data_Science\\Statistics")
x<-c(1,12,30,54,5)
length(x)
x<-c(1,12,30,54,5)
x<-c(1,12,30,54,5)
length(x)
typeof(x)
x[2]
x<-c(x,8)
x
x=c(x,"cat")
typeof(x)
x[1:3]
x[x>5]
x<-c(1,12,30,54,5)
length(x)
typeof(x)
x[2]
x<-c(x,8)
x
x[x>5]
#sequence of numbers
series <-1:10
seq(10)
#sequence of numbers
series <-1:10
series
y=seq(1,10,by=2)
y
typeof(y)
typeof(as.integer(y))
typeof(y)
## MATRIX: 2D vector
m <- matrix(1:6. mrow = 2, ncol = 3)
## MATRIX: 2D vector
m <- matrix(1:6. nrow = 2, ncol = 3)
## MATRIX: 2D vector
m <- matrix(1:6, nrow = 2, ncol = 3)
m
m2<-matrix(1:6, nrow=3,ncol = 2)
n2
m2
m2<-matrix(1:6, nrow=3,ncol = 1)
m2
m2<-matrix(1:6, nrow=3)
m2
m2<-matrix(1:6, nrow=3, ncol = 2)
m2
# bind columns of two vectors to create a matrix
x <- 1:4
y<-10:13
cbind(x,y)
nrow(cbind(x,y))
nrow(cbind(x,y))
ncol(cbind(x,y))
rbind(x,y)
df1
df1=as.data.frame((cbind(x,y))) #convert to a data frame
df1
str(df1)
install.packages(datasets)
install.packages("datasets")
installed.packages()
length(df1)
data()
data(package="datasets")
data()
data("ChickWeight")
str(ChickWeight)
head(ChickWeight)
typeof(ChickWeight['Chick'])
typeof(ChickWeight.Diet)
typeof(ChickWeight[Diet])
knitr::opts_chunk$set(echo = TRUE)
# Setting working directory
setwd("C:\\Users\\kbrown5\\Documents\\Data_Science\\Statistics")
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
View(married_sal)
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
# View the head
head(married_sal)
# View the structure
str(married_sal)
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
# View the head
head(married_sal)
# Read in text file
married_sal2<-read.table("family-households-with-married-couples.txt",header=T)
# View the head
head(married_sal2)
# View the structure
str(married_sal2)
red_wine<-read.csv("winequality-red.csv", header=T, sep=';')
install.packages(readxl)
installed.packages()
install.packages('readx;')
install.packages('readxl')
library(readxl)
a <- array(rnorm(2*2*10), c(2,2,10))
a
apply(a,c(1,2), mean'')
apply(a,c(1,2), mean)
x <- matrix(rnorm(200),20,10)
x
apply(x,1,sum)
x[,1]
mean(x[,1])
sum(x[,])
sum(x[,1])
x
apply(x,1,sum)
apply(x,2,sum)
rowSums(x)
colSums(x)
x
apply(x,1,quantile,probs=c(0.25,0.75))
quantile(x[1,],probs=0.25)
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
f
split(x,f)
l1 <- split(x,f)
l1
l1$1
l1[1]
l1[2]
library(datasets)
data(iris)
?iris
head(iris)
factor(iris$Species)
tapply(iris,iris$Species,mean)
tapply(iris$Sepal.Length,iris$Species,mean)
iris(head)
head(iris)
colmeans(iris)
colMeans(iris)
colMeans(iris)
apply(iris[, 1:4], 2, mean)
class(apply(iris[, 1:4], 2, mean))
library(datasets)
data(mtcars)
head(mtcars)
tapply(mtcars$mpg,mtcars$cyl,mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(mtcars, cyl, mean)
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
head(mtcars)
tapply(mtcars$hp,mtcars$cyl,mean)
x <- tapply(mtcars$hp,mtcars$cyl,mean)
y <- x[1] - x[3]
debug(ls)
?ks
?ls
exit()
## xml
library(httr)
library(XML)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/beds-1/baths-1/pg-2'
r = GET(fileURL)
doc <- htmlTreeParse(fileURL, useInternal=TRUE, isURL=T)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(fileURL, useInternal=TRUE, isURL=T)
doc <- htmlTreeParse(r, useInternal=TRUE, isURL=T)
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
?GET
## xml
library(httr)
library(XML)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
doc <- xmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
street <- xpathSApply(doc, "//span[@class='listing-street-address']",xmlValue)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(r, useText = TRUE)
doc <- htmlTreeParse(r, asText = TRUE)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
content2 <- content(r,as="text")
content
?content
content2 <- content(r,as="text",encoding="UTF-8")
doc <- htmlParse(content2, asText = TRUE)
street <- xpathSApply(doc, "//span[@class='listing-street-address']",xmlValue)
city <- xpathSApply(doc, "//span[@class='listing-city']",xmlValue)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url,destfile = 'idaho_microdata.csv',method = 'curl')
id_df <- read.csv('idaho_microdata.csv')
gdp_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(gdp_url, destfile = 'gdp.csv',method='curl')
gdp_df <- read.csv('gdp.csv')
edu_df <- read.csv('edu.csv')
edu_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(edu_url, destfile = 'edu.csv', method='curl')
edu_df <- read.csv('edu.csv')
head(gdp_df)
getwd()
setwd("C:/Users/kbrown5/Documents/Data_Science/datasciencecoursera/3_GCD")
gdp_df <- read.csv('gdp.csv')
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
?read.csv
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(edu_df)
head(edu_df)
head(gdp_df)
tail(gdp_df)
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
head(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x = "CountryCode")
head(merge_data)
merge_data <- merge(gdp_df,edu_df,by.x = "CountryCode",by.y="CountryCode")
head(merge_data)
merge_data <- merge(gdp_df,edu_df.by.y="CountryCode")
merge_data <- merge(gdp_df,edu_df,by.y="CountryCode")
View(merge_data)
sorted_data <- arrange(merge_data,desc(Ranking))
tail(sorted_data)
tail(gdp_df)
tail(gdp_df,20)
gdp_r <- gdp_df[1:214,]
tail(gdp_r)
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
sorted_data[13]
names(sorted_data)
sorted_data[13,5]
summarize(sorted_data)
View(sorted_data)
View(merge_data)
View(sorted_data)
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
View(income.groups)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
?dplyr
?cut
gdp_groups <- cut(merge_data$Ranking, breaks=quantile(merge_data$Ranking))
gdp_groups <- cut(merge_data$Ranking, breaks=quantile(merge_data$Ranking,na.rm = TRUE))
table(gdp_groups)
gdp_groups <- cut(merge_data$Ranking, breaks=quantile(merge_data$Ranking,probs = c(.20,.40,.60,.80),na.rm = TRUE))
table(gdp_groups)
gdp_groups <- cut(merge_data$Ranking, breaks=5)
table(gdp_groups)
merge_data$gdp_groups <- cut(merge_data$Ranking, breaks=5)
head(merge_data)
table(merge_data$gdp_groups)
table(merge_data$gdp_groups,merge_data$Income.Group)
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
sorted_data[13,5]
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
download.file(url,destfile = 'idaho_microdata.csv',method = 'curl')
id_df <- read.csv('idaho_microdata.csv')
head(id_df)
id_df$ACR == 3 && id_df$AGS == 6
agricultureLogical <- id_df$ACR == 3 & id_df$AGS == 6
id_df[which(agricultureLogical),]
id_df[which(agricultureLogical),]
head(id_df[which(agricultureLogical),],3)
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
install.packages('jpeg')
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
gdp_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
download.file(gdp_url, destfile = 'gdp.csv',method='curl')
edu_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
download.file(edu_url, destfile = 'edu.csv', method='curl')
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
names(gdp_df)
names(edu_df)
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
gdp_r <- gdp_df[1:214,]
names(gdp_df)
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
names(gdp_df)
names(edu_df)
head(gdp_df)
gdp_df <- read.csv('gdp.csv',na.strings = "..")
edu_df <- read.csv('edu.csv')
head(gdp_df)
head(edu_df)
merge_data <- merge(gdp_r,edu_df,by.y="CountryCode",by.x="X")
merge_data <- merge(gdp_df,edu_df,by.y="CountryCode",by.x="X")
View(merge_data)
View(merge_data)
sorted_data <- arrange(merge_data,desc(Ranking))
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
table(income.groups)
head(edu_df)
table(income.groups)
merge_data <- merge(gdp_df,edu_df,by.x="X")
gdp_df <- rename(gdp_df, CountryCode = X)
names(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
library(dplyr)
gdp_df <- rename(gdp_df, CountryCode = X)
names(gdp_df)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
View(sorted_data)
# finding average GPD ranking among different income groups
income.groups <- group_by(merge_data,Income.Group)
income.groups
# finding average GPD ranking among different income groups
income.groups <- group_by(sorted_data,Income.Group)
summarize(income.groups,Ranking = mean(Ranking, na.rm = TRUE))
gdp_df <- read.csv('gdp.csv',na.strings = c("..",""))
gdp_df <- rename(gdp_df, CountryCode = X)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
head(sorted_data)
View(sorted_data)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
View(merge_data)
View(sorted_data)
gdp_df <- read.csv('gdp.csv')
edu_df <- read.csv('edu.csv')
gdp_df <- rename(gdp_df, CountryCode = X)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
head(sorted_data)
gdp_df <- read.csv('gdp.csv', stringsAsFactors = FALSE)
gdp_df <- rename(gdp_df, CountryCode = X)
names(gdp_df)
class(gdp_df$Ranking)
gdp_df$Ranking<-as.numeric(gdp_df$Ranking)
merge_data <- merge(gdp_df,edu_df,by.x="CountryCode")
sorted_data <- arrange(merge_data,desc(Ranking))
head(sorted_data
)
View(sorted_data)
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
library(jpeg)
img_url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
download.file(img_url, destfile = 'jeff.jpg')
img <- readJPEG('jeff.jpg', native = TRUE)
quantile(img, c(.30,.80))
