library(caret)
install.packages(caret)
x<-c(1,2,3)
y<-c(4,5,6)
z<-c(x,y)
9+9
setwd("C:\Users\kbrown5\Documents\Data_Science\Statistics")
setwd("C:\\Users\\kbrown5\\Documents\\Data_Science\\Statistics")
x<-c(1,12,30,54,5)
length(x)
x<-c(1,12,30,54,5)
x<-c(1,12,30,54,5)
length(x)
typeof(x)
x[2]
x<-c(x,8)
x
x=c(x,"cat")
typeof(x)
x[1:3]
x[x>5]
x<-c(1,12,30,54,5)
length(x)
typeof(x)
x[2]
x<-c(x,8)
x
x[x>5]
#sequence of numbers
series <-1:10
seq(10)
#sequence of numbers
series <-1:10
series
y=seq(1,10,by=2)
y
typeof(y)
typeof(as.integer(y))
typeof(y)
## MATRIX: 2D vector
m <- matrix(1:6. mrow = 2, ncol = 3)
## MATRIX: 2D vector
m <- matrix(1:6. nrow = 2, ncol = 3)
## MATRIX: 2D vector
m <- matrix(1:6, nrow = 2, ncol = 3)
m
m2<-matrix(1:6, nrow=3,ncol = 2)
n2
m2
m2<-matrix(1:6, nrow=3,ncol = 1)
m2
m2<-matrix(1:6, nrow=3)
m2
m2<-matrix(1:6, nrow=3, ncol = 2)
m2
# bind columns of two vectors to create a matrix
x <- 1:4
y<-10:13
cbind(x,y)
nrow(cbind(x,y))
nrow(cbind(x,y))
ncol(cbind(x,y))
rbind(x,y)
df1
df1=as.data.frame((cbind(x,y))) #convert to a data frame
df1
str(df1)
install.packages(datasets)
install.packages("datasets")
installed.packages()
length(df1)
data()
data(package="datasets")
data()
data("ChickWeight")
str(ChickWeight)
head(ChickWeight)
typeof(ChickWeight['Chick'])
typeof(ChickWeight.Diet)
typeof(ChickWeight[Diet])
knitr::opts_chunk$set(echo = TRUE)
# Setting working directory
setwd("C:\\Users\\kbrown5\\Documents\\Data_Science\\Statistics")
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
View(married_sal)
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
# View the head
head(married_sal)
# View the structure
str(married_sal)
# Read in csv
married_sal<-read.csv("family-households-with-married-couples.csv",header=T)
# View the head
head(married_sal)
# Read in text file
married_sal2<-read.table("family-households-with-married-couples.txt",header=T)
# View the head
head(married_sal2)
# View the structure
str(married_sal2)
red_wine<-read.csv("winequality-red.csv", header=T, sep=';')
install.packages(readxl)
installed.packages()
install.packages('readx;')
install.packages('readxl')
library(readxl)
a <- array(rnorm(2*2*10), c(2,2,10))
a
apply(a,c(1,2), mean'')
apply(a,c(1,2), mean)
x <- matrix(rnorm(200),20,10)
x
apply(x,1,sum)
x[,1]
mean(x[,1])
sum(x[,])
sum(x[,1])
x
apply(x,1,sum)
apply(x,2,sum)
rowSums(x)
colSums(x)
x
apply(x,1,quantile,probs=c(0.25,0.75))
quantile(x[1,],probs=0.25)
x <- c(rnorm(10), runif(10), rnorm(10, 1))
f <- gl(3, 10)
f
split(x,f)
l1 <- split(x,f)
l1
l1$1
l1[1]
l1[2]
library(datasets)
data(iris)
?iris
head(iris)
factor(iris$Species)
tapply(iris,iris$Species,mean)
tapply(iris$Sepal.Length,iris$Species,mean)
iris(head)
head(iris)
colmeans(iris)
colMeans(iris)
colMeans(iris)
apply(iris[, 1:4], 2, mean)
class(apply(iris[, 1:4], 2, mean))
library(datasets)
data(mtcars)
head(mtcars)
tapply(mtcars$mpg,mtcars$cyl,mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(mtcars, cyl, mean)
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
head(mtcars)
tapply(mtcars$hp,mtcars$cyl,mean)
x <- tapply(mtcars$hp,mtcars$cyl,mean)
y <- x[1] - x[3]
debug(ls)
?ks
?ls
exit()
## xml
library(httr)
library(XML)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/beds-1/baths-1/pg-2'
r = GET(fileURL)
doc <- htmlTreeParse(fileURL, useInternal=TRUE, isURL=T)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(fileURL, useInternal=TRUE, isURL=T)
doc <- htmlTreeParse(r, useInternal=TRUE, isURL=T)
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
?GET
## xml
library(httr)
library(XML)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
doc <- xmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
doc <- htmlTreeParse(r, useInternal=TRUE, encoding = 'UTF-8')
street <- xpathSApply(doc, "//span[@class='listing-street-address']",xmlValue)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
doc <- htmlTreeParse(r, useText = TRUE)
doc <- htmlTreeParse(r, asText = TRUE)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
content2 <- content(r,as="text")
content
?content
content2 <- content(r,as="text",encoding="UTF-8")
doc <- htmlParse(content2, asText = TRUE)
street <- xpathSApply(doc, "//span[@class='listing-street-address']",xmlValue)
city <- xpathSApply(doc, "//span[@class='listing-city']",xmlValue)
fileURL <- 'https://www.realtor.com/realestateandhomes-search/San-Antonio_TX/pg-1'
r = GET(fileURL)
setInternet2(use=TRUE)
data(spam)
library(kernlab)
install.packages('kernlab')
data(spam)
library(kernlab)
data(spam)
# perform the subsampling
set.seed(3435)
trainIndicator <- rbinom(4601, size = 1, prob=0.5)
table(trainIndicator)
trainSpam <- spam[trainIndicator,]
trainSpam <- spam[trainIndicator==1,]
trainSpam <- spam[trainIndicator,]
trainSpam <- spam[!trainIndicator,]
trainSpam <- spam[trainIndicator,]
testSpam <- spam[!trainIndicator,]
#Look at summaries of data
names(trainSpam)
head(trainSpam)
table(trainSpam)
table(trainSpam$type)
trainSpam <- spam[trainIndicator==1,]
testSpam <- spam[trainIndicator==0,]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
# look at plots
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4]+1))
# exploratory analysis
hCluster <- hclust(dist(t(trainSpam[,1:57])))
plot(hCluster)
# redo cluster after transformation
hClusterUpdated <- hclust(dist(t(log10(trainSpam[,1:55] + 1)))
# redo cluster after transformation
hClusterUpdated <- hclust(dist(t(log10(trainSpam[,1:55] + 1))))
# redo cluster after transformation
hClusterUpdated <- hclust(dist(t(log10(trainSpam[,1:55] + 1))))
plot(hClusterUpdated)
# statistical model
trainSpam$numType <- as.numeric(trainSpam$type) - 1
costFunction = function(x,y) sum(x != (y > 0.5))
library(boot)
cvError = rep(NA, 55)
for (i in 1:55) {
lmFormula <- reformulate(names(trainSpam)[i], response = 'numType')
glmFit <- glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] <- cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
# predict
predictionModel <- glm(numType ~ charDollar, family = "binomial", data = trainSpam)
# predict
predictionModel <- glm(numType ~ charDollar, family = "binomial", data = trainSpam)
# get predictions on the test set
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
# Classification
table(predictedSpam, testSpam$table)
# Classification
table(predictedSpam, testSpam$type)
# Error rate
(61 + 458) / (1346 + 458 + 61 + 449)
predictedSpam[predictionModel$fitted > 0.7] = "spam"
# Classification
table(predictedSpam, testSpam$type)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.7] = "spam"
# Classification
table(predictedSpam, testSpam$type)
# Error rate
# Error rate
(41 + 546) / (1366 + 546 + 41 + 361)
predictedSpam[predictionModel$fitted > 0.4] = "spam"
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.4] = "spam"
# Classification
table(predictedSpam, testSpam$type)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.8] = "spam"
# Classification
table(predictedSpam, testSpam$type)
# get predictions on the test set
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
# Classification
table(predictedSpam, testSpam$type)
# Error rate
(61 + 458) / (1346 + 449 + 61 + 458)
getwd()
setwd(paste0(getwd(),'/Data_Science/datasciencecoursera/5_RR')
)
getwd()
# Download file
if(!file.exists("./data")) {
dir.creat("./data")
}
if(!file.exists("./data/activity.zip")) {
url <- 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip'
download.file(url, destfile = './data/activity.zip',method='curl' )
}
if(!file.exists("./data/activity.csv")) {
unzip('./data/activity.zip',exdir = './data')
}
# Download file
if(!file.exists("./data")) {
dir.create("./data")
}
if(!file.exists("./data/activity.zip")) {
url <- 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip'
download.file(url, destfile = './data/activity.zip',method='curl' )
}
if(!file.exists("./data/activity.csv")) {
unzip('./data/activity.zip',exdir = './data')
}
# Read in data
data <- read.csv('data/activity.csv')
# Look at data
names(data)
head(data,20)
# Look at data
str(activity)
# Read in data
activity <- read.csv('data/activity.csv')
library(dplyr)
# Create directory (add this directory to .gitignore file)
if(!file.exists("./data")) {
dir.create("./data")
}
# Download file
if(!file.exists("./data/activity.zip")) {
url <- 'https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip'
download.file(url, destfile = './data/activity.zip',method='curl' )
}
# Unzip file
if(!file.exists("./data/activity.csv")) {
unzip('./data/activity.zip',exdir = './data')
}
# Read in data
activity <- read.csv('data/activity.csv')
# Look at data
str(activity)
names(activity)
head(activity,20)
# Change column 2 to date object
activity$date <- as.Date(activity$date, format = "%Y-%m-%d")
# Look at data
str(activity)
# Read in data
activity <- read.csv('data/activity.csv')
# Look at data
str(activity)
names(activity)
head(activity,20)
# histogram of number of steps
sum(steps)
# histogram of number of steps
sum(activity$steps)
# histogram of number of steps
sum(activity$steps, na.rm = TRUE)
?sapply
?tapply
# histogram of number of steps
tapply(activity,activity$date,sum(activity$steps, na.rm = TRUE)
)
# histogram of number of steps
tapply(activity,activity$date,sum(activity$steps, na.rm = TRUE))
# histogram of number of steps
tapply(activity,activity$date,FUN=sum(activity$steps, na.rm = TRUE))
# histogram of number of steps
tapply(activity$steps,activity$date,FUN=sum(na.rm = TRUE))
# histogram of number of steps
tapply(activity$steps, activity$date, FUN=sum)
# histogram of number of steps
tapply(activity$steps, activity$date, FUN=sum(rm.na=TRUE))
# histogram of number of steps
step_by_day <- aggregate(sum,activity$steps, activity$date, na.action = na.omit)
# histogram of number of steps
step_by_day <- aggregate(activity$steps, by=list(activity$day), FUN=sum, na.action=na.omit)
list(acitivty$day)
list(activity$day)
activity$day
names(activity)
# histogram of number of steps
step_by_day <- aggregate(activity$steps, by=list(activity$date), FUN=sum, na.action=na.omit)
activity$date
# histogram of number of steps
step_by_day <- aggregate(activity$steps, by=activity$date, FUN=sum, na.action=na.omit)
# histogram of number of steps
step_by_day <- aggregate(activity$steps, by=list(activity$date), FUN=sum, na.action=na.omit)
list(activity$date)
step_by_day <- aggregate(activity$steps, by=list(activity$date), FUN=sum, na.action=na.omit)
# histogram of number of steps
step_by_day <- aggregate(x=activity$steps, by=list(activity$date), FUN=sum, na.action=na.omit)
# histogram of number of steps
step_by_day <- aggregate(x=activity, by=list(activity$date), FUN=sum, na.action=na.omit)
# histogram of number of steps
tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE)
class(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
# histogram of number of steps
barplot(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
library(ggplot2)
# Basic histogram
ggplot(activity, aes(x=value)) + geom_histogram()
# Basic histogram
ggplot(activity$steps, aes(x=activity$date)) + geom_histogram()
# Basic histogram
ggplot(activity, aes(x=activity$date)) + geom_histogram()
barplot(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
data <- tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE)
data
as.data.frame(data)
data <- as.data.frame(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
ggplot(data, aes(x=as.Date(activity$date))) + geom_histogram()
ggplot(data) + geom_histogram()
nrow(data)
# notices some na's so I will keep that in mind when doing histogram
data <- as.data.frame(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
View(data)
# notices some na's so I will keep that in mind when doing histogram
data <- as.data.frame(steps=tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
# notices some na's so I will keep that in mind when doing histogram
data <- tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE)
data <- as.data.frame(data)
View(data)
names(data)
?hist
hist(data)
class(data$data)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE))
class(activity$date)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), bins = 10)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), bin = 10)
?hist
?hist
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 10)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 20)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 30)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 30)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 5)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 15)
# notices some na's so I will keep that in mind when doing histogram
hist(tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE), breaks = 20)
# notices some na's so I will keep that in mind when doing histogram
data <- tapply(activity$steps, activity$date, FUN=sum,na.rm=TRUE)
qplot(data, geom="histogram")
ggplot() + aes(data)+ geom_histogram(binwidth=1, colour="black", fill="white")
ggplot() + aes(data)+ geom_histogram(binwidth=20, colour="black", fill="white")
ggplot() + aes(data)+ geom_histogram(binwidth=40, colour="black", fill="white")
ggplot() + aes(data)+ geom_histogram(binwidth=400, colour="black", fill="white")
?brewer
?brewer.pal
library(RColorBrewer)
?brewer
display.brewer.all
display.brewer.all()
## creating color palette
shades <- brewer.pal(8, "PuBl")
## creating color palette
shades <- brewer.pal(8, "PuBu")
shades
brewr.pal(shades)
brewer.pal(shades)
?brewer
display.brewer.pal(shades)
display.brewer.pal(name=shades)
display.brewer.pal(name='PuBu')
display.brewer.pal(8,name='PuBu')
ggplot() + aes(data)+ geom_histogram(binwidth=400, colour="black", fill=shades[3])
ggplot() + aes(data)+ geom_histogram(binwidth=400, colour="shades[5]", fill=shades[3])
ggplot() + aes(data)+ geom_histogram(binwidth=400, colour=shades[5], fill=shades[3])
ggplot() + aes(data)+ geom_histogram(binwidth=400, colour=shades[5], fill=shades[4])
ggplot(data, aes(x = data)) +
geom_histogram(aes(y = ..count..), binwidth = 5)
ggplot(as.data.frame(data), aes(x = data)) +
geom_histogram(aes(y = ..count..), binwidth = 5)
ggplot(as.data.frame(data), aes(x = data)) +
geom_histogram(aes(y = ..count..), binwidth = 500)
ggplot() + aes(data)+ geom_histogram(binwidth=400, colour=shades[5], fill=shades[4])
ggplot(as.data.frame(data), aes(x = data)) +
geom_histogram(aes(y = ..count..), binwidth = 600)
ggplot() + aes(data)+ geom_histogram(binwidth=600, colour=shades[5], fill=shades[4])
